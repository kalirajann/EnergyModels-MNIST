{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Environment and seeds initialized\n",
      "TensorFlow version: 2.12.1\n",
      "Random seed set to: 42\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports + Global Seed Initialization\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "\n",
    "print(\"Step 1: Environment and seeds initialized\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Random seed set to: {SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Loading MNIST dataset...\n",
      "Training set shape: (60000, 28, 28)\n",
      "Test set shape: (10000, 28, 28)\n",
      "Pixel value range (before normalization): [0, 255]\n",
      "After normalization - Training range: [-1.000, 1.000]\n",
      "After normalization - Test range: [-1.000, 1.000]\n",
      "Step 2: MNIST data loaded and preprocessed\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: MNIST Loading and Preprocessing\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Loading MNIST dataset...\")\n",
    "\n",
    "# Load MNIST\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print(f\"Training set shape: {x_train.shape}\")\n",
    "print(f\"Test set shape: {x_test.shape}\")\n",
    "print(f\"Pixel value range (before normalization): [{x_train.min()}, {x_train.max()}]\")\n",
    "\n",
    "# Reshape to flat vectors (28x28 -> 784)\n",
    "x_train = x_train.reshape(x_train.shape[0], 784).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], 784).astype('float32')\n",
    "\n",
    "# Normalize to [-1, 1] range\n",
    "# Rationale: This range provides better gradient flow for energy-based models\n",
    "# compared to [0,1], as it centers the data around zero\n",
    "x_train = (x_train / 127.5) - 1.0\n",
    "x_test = (x_test / 127.5) - 1.0\n",
    "\n",
    "print(f\"After normalization - Training range: [{x_train.min():.3f}, {x_train.max():.3f}]\")\n",
    "print(f\"After normalization - Test range: [{x_test.min():.3f}, {x_test.max():.3f}]\")\n",
    "print(\"Step 2: MNIST data loaded and preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Creating TensorFlow datasets...\n",
      "Batch size: 128\n",
      "Number of training batches: 469\n",
      "Number of test batches: 79\n",
      "Total training samples: 60000\n",
      "Total test samples: 10000\n",
      "Step 3: tf.data pipelines ready\n",
      "\n",
      "Sample batch shape: (128, 784)\n",
      "Sample batch value range: [-1.000, 1.000]\n",
      "\n",
      "Datasets saved to 'data/' directory\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Dataset Batching and Shuffling\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Creating TensorFlow datasets...\")\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "SHUFFLE_BUFFER = 10000\n",
    "\n",
    "# Create tf.data.Dataset objects\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER, seed=SEED)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Number of training batches: {len(list(train_dataset))}\")\n",
    "print(f\"Number of test batches: {len(list(test_dataset))}\")\n",
    "print(f\"Total training samples: {len(x_train)}\")\n",
    "print(f\"Total test samples: {len(x_test)}\")\n",
    "print(\"Step 3: tf.data pipelines ready\")\n",
    "\n",
    "# Verify one batch\n",
    "sample_batch = next(iter(train_dataset))\n",
    "print(f\"\\nSample batch shape: {sample_batch.shape}\")\n",
    "print(f\"Sample batch value range: [{sample_batch.numpy().min():.3f}, {sample_batch.numpy().max():.3f}]\")\n",
    "\n",
    "# Save datasets for use in other notebooks\n",
    "import pickle\n",
    "\n",
    "os.makedirs('data', exist_ok=True)\n",
    "with open('data/train_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump(x_train, f)\n",
    "with open('data/test_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump(x_test, f)\n",
    "\n",
    "print(\"\\nDatasets saved to 'data/' directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation Summary\n",
    "\n",
    "**Assumptions and Choices:**\n",
    "- **Normalization Range**: [-1, 1] was chosen over [0, 1] to center the data distribution around zero, which typically improves gradient flow in energy-based training.\n",
    "- **Batch Size**: 128 samples per batch provides a good balance between gradient stability and computational efficiency.\n",
    "- **Shuffling**: A buffer size of 10,000 ensures good randomization without excessive memory usage.\n",
    "- **Data Shape**: Images are flattened to 784-dimensional vectors to simplify the energy network architecture.\n",
    "- **No Data Augmentation**: For this initial implementation, we use raw MNIST without augmentation to establish baseline behavior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Energy Models MNIST)",
   "language": "python",
   "name": "energy-models-mnist"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
